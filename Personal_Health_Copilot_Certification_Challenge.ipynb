{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Problem and Audience\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Users struggle to understand complex medical information, lab results, and medication interactions, leading to confusion and potential health risks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== User Personas ===\n",
      "\n",
      "Chronic Illness Patient:\n",
      "  Job Title: Patient with Chronic Condition\n",
      "  Function: Self-managing health conditions\n",
      "  Automation Target: Medical information interpretation and decision support\n",
      "  Pain Points: Complex lab result interpretation, Medication interaction concerns, Symptom tracking and analysis, Treatment option understanding\n",
      "\n",
      "Health Conscious Individual:\n",
      "  Job Title: Health-Conscious Individual\n",
      "  Function: Preventive health monitoring\n",
      "  Automation Target: Health information and wellness guidance\n",
      "  Pain Points: Understanding preventive health metrics, Lifestyle recommendations, Supplement interaction checking, Wellness goal tracking\n",
      "\n",
      "Caregiver:\n",
      "  Job Title: Family Caregiver\n",
      "  Function: Supporting loved ones' health\n",
      "  Automation Target: Medical decision support and information synthesis\n",
      "  Pain Points: Understanding medical reports for others, Medication management for multiple people, Emergency health decision making, Communication with healthcare providers\n",
      "\n",
      "=== Potential User Questions ===\n",
      "1. What do these lab results mean?\n",
      "2. Are these medication interactions safe?\n",
      "3. What could be causing these symptoms?\n",
      "4. How do I interpret this blood test?\n",
      "5. What are the side effects of this medication?\n",
      "6. Is this normal for my age and condition?\n",
      "7. What lifestyle changes should I make?\n",
      "8. How do I track my symptoms over time?\n",
      "9. What questions should I ask my doctor?\n",
      "10. Are there alternative treatments available?\n"
     ]
    }
   ],
   "source": [
    "# Task 1: User Analysis and Potential Questions\n",
    "\n",
    "# Define user personas and their potential questions\n",
    "user_personas = {\n",
    "    \"chronic_illness_patient\": {\n",
    "        \"job_title\": \"Patient with Chronic Condition\",\n",
    "        \"function\": \"Self-managing health conditions\",\n",
    "        \"automation_target\": \"Medical information interpretation and decision support\",\n",
    "        \"pain_points\": [\n",
    "            \"Complex lab result interpretation\",\n",
    "            \"Medication interaction concerns\", \n",
    "            \"Symptom tracking and analysis\",\n",
    "            \"Treatment option understanding\"\n",
    "        ]\n",
    "    },\n",
    "    \"health_conscious_individual\": {\n",
    "        \"job_title\": \"Health-Conscious Individual\",\n",
    "        \"function\": \"Preventive health monitoring\",\n",
    "        \"automation_target\": \"Health information and wellness guidance\",\n",
    "        \"pain_points\": [\n",
    "            \"Understanding preventive health metrics\",\n",
    "            \"Lifestyle recommendations\",\n",
    "            \"Supplement interaction checking\",\n",
    "            \"Wellness goal tracking\"\n",
    "        ]\n",
    "    },\n",
    "    \"caregiver\": {\n",
    "        \"job_title\": \"Family Caregiver\",\n",
    "        \"function\": \"Supporting loved ones' health\",\n",
    "        \"automation_target\": \"Medical decision support and information synthesis\",\n",
    "        \"pain_points\": [\n",
    "            \"Understanding medical reports for others\",\n",
    "            \"Medication management for multiple people\",\n",
    "            \"Emergency health decision making\",\n",
    "            \"Communication with healthcare providers\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Potential questions users would ask\n",
    "potential_questions = [\n",
    "    \"What do these lab results mean?\",\n",
    "    \"Are these medication interactions safe?\",\n",
    "    \"What could be causing these symptoms?\",\n",
    "    \"How do I interpret this blood test?\",\n",
    "    \"What are the side effects of this medication?\",\n",
    "    \"Is this normal for my age and condition?\",\n",
    "    \"What lifestyle changes should I make?\",\n",
    "    \"How do I track my symptoms over time?\",\n",
    "    \"What questions should I ask my doctor?\",\n",
    "    \"Are there alternative treatments available?\"\n",
    "]\n",
    "\n",
    "print(\"=== User Personas ===\")\n",
    "for persona, details in user_personas.items():\n",
    "    print(f\"\\n{persona.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Job Title: {details['job_title']}\")\n",
    "    print(f\"  Function: {details['function']}\")\n",
    "    print(f\"  Automation Target: {details['automation_target']}\")\n",
    "    print(f\"  Pain Points: {', '.join(details['pain_points'])}\")\n",
    "\n",
    "print(\"\\n=== Potential User Questions ===\")\n",
    "for i, question in enumerate(potential_questions, 1):\n",
    "    print(f\"{i}. {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Proposed Solution and Tooling Stack\n",
    "\n",
    "The Personal Health Copilot will be a conversational web application that feels like having a knowledgeable medical assistant at your fingertips. Users will interact with a clean, chat-based interface where they can upload lab reports, describe symptoms, or ask questions about medications. The system will respond with clear, personalized explanations written in plain language, avoiding medical jargon while maintaining accuracy.\n",
    "\n",
    "For lab results, it will highlight abnormal values and explain what they mean for the user's specific health context. The interface will include visual elements like charts and progress indicators, and users can save their health history for personalized future interactions. The system will integrate with external APIs to provide real-time drug interaction checking and up-to-date medical information from verified sources like Mayo Clinic and NIH.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tooling Stack Initialized ===\n",
      "LLM: gpt-4o\n",
      "Embedding Model: text-embedding-3-small\n",
      "Text Splitter: RecursiveCharacterTextSplitter\n",
      "LangSmith Project: personal-health-copilot-certification\n",
      "LangSmith Tracing: true\n",
      "\n",
      "=== Agent Configuration ===\n",
      "llm: client=<openai.resources.chat.completions.completions.Completions object at 0x77c61a1ce7b0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x77c61a1cf230> root_client=<openai.OpenAI object at 0x77c61a1cc050> root_async_client=<openai.AsyncOpenAI object at 0x77c61a1cef90> model_name='gpt-4o' temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********') streaming=True\n",
      "embedding_model: client=<openai.resources.embeddings.Embeddings object at 0x77c61a1cf4d0> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x77c61a1cf770> model='text-embedding-3-small' dimensions=1536 deployment='text-embedding-ada-002' openai_api_version=None openai_api_base=None openai_api_type=None openai_proxy=None embedding_ctx_length=8191 openai_api_key=SecretStr('**********') openai_organization=None allowed_special=None disallowed_special=None chunk_size=1000 max_retries=2 request_timeout=None headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None http_async_client=None check_embedding_ctx_length=True\n",
      "text_splitter: <langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x77c61a1cf8c0>\n",
      "vector_store: Qdrant\n",
      "orchestration: LangGraph\n",
      "monitoring: LangSmith\n",
      "evaluation: RAGAS\n",
      "\n",
      "=== Agentic Reasoning Plan ===\n",
      "Multi-Agent System:\n",
      "• Symptom Analysis Agent\n",
      "• Lab Results Agent\n",
      "• Medication Agent\n",
      "• Research Agent\n",
      "• Coordinator Agent\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Tooling Stack Configuration\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langsmith import Client\n",
    "\n",
    "# API Keys Setup (following instructor's pattern)\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass(\"Enter your Tavily API key: \")\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass(\"Enter your Cohere API key: \")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass(\"Enter your LangSmith API key: \")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"personal-health-copilot-certification\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # Enable LangSmith tracing\n",
    "\n",
    "# Initialize LangSmith client for tracing\n",
    "langsmith_client = Client()\n",
    "\n",
    "# Initialize models (following patterns from previous notebooks)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536\n",
    ")\n",
    "\n",
    "# Text splitter configuration (from 02_Embeddings_and_RAG patterns)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "print(\"=== Tooling Stack Initialized ===\")\n",
    "print(f\"LLM: {llm.model_name}\")\n",
    "print(f\"Embedding Model: {embedding_model.model}\")\n",
    "print(f\"Text Splitter: {text_splitter.__class__.__name__}\")\n",
    "print(f\"LangSmith Project: {os.environ['LANGCHAIN_PROJECT']}\")\n",
    "print(f\"LangSmith Tracing: {os.environ['LANGCHAIN_TRACING_V2']}\")\n",
    "\n",
    "# Agent configuration (following 05_Our_First_Agent_with_LangGraph patterns)\n",
    "agent_config = {\n",
    "    \"llm\": llm,\n",
    "    \"embedding_model\": embedding_model,\n",
    "    \"text_splitter\": text_splitter,\n",
    "    \"vector_store\": \"Qdrant\",\n",
    "    \"orchestration\": \"LangGraph\",\n",
    "    \"monitoring\": \"LangSmith\",\n",
    "    \"evaluation\": \"RAGAS\"\n",
    "}\n",
    "\n",
    "print(\"\\n=== Agent Configuration ===\")\n",
    "for key, value in agent_config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n=== Agentic Reasoning Plan ===\")\n",
    "print(\"Multi-Agent System:\")\n",
    "print(\"• Symptom Analysis Agent\")\n",
    "print(\"• Lab Results Agent\") \n",
    "print(\"• Medication Agent\")\n",
    "print(\"• Research Agent\")\n",
    "print(\"• Coordinator Agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Dealing with the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Directory Structure Created ===\n",
      "data/\n",
      "=== Downloading Real Medical Documents ===\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  658k    0  658k    0     0   857k      0 --:--:-- --:--:-- --:--:--  864k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1830k    0 1830k    0     0  2107k      0 --:--:-- --:--:-- --:--:-- 2123k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  700k    0  700k    0     0  1348k      0 --:--:-- --:--:-- --:--:-- 1351k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  658k    0  658k    0     0  1970k      0 --:--:-- --:--:-- --:--:-- 1982k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  664k    0  664k    0     0   721k      0 --:--:-- --:--:-- --:--:--  721k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 37604  100 37604    0     0   147k      0 --:--:-- --:--:-- --:--:--  148k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 39198  100 39198    0     0   321k      0 --:--:-- --:--:-- --:--:--  324k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 29454  100 29454    0     0   207k      0 --:--:-- --:--:-- --:--:--  208k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 29454  100 29454    0     0   289k      0 --:--:-- --:--:-- --:--:--  293k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 14526  100 14526    0     0  42015      0 --:--:-- --:--:-- --:--:-- 42104\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   420    0   420    0     0   2088      0 --:--:-- --:--:-- --:--:--  2100\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 34912  100 34912    0     0   106k      0 --:--:-- --:--:-- --:--:--  106k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 53450  100 53450    0     0   246k      0 --:--:-- --:--:-- --:--:--  247k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 47023  100 47023    0     0   192k      0 --:--:-- --:--:-- --:--:--  192k\n",
      "✅ Real medical documents downloaded successfully!\n",
      "=== Loading Medical Documents ===\n",
      "✅ Loaded 14 medical documents\n",
      "\n",
      "=== Chunking Strategy ===\n",
      "Chunk Size: 1200 tokens (medical-optimized)\n",
      "Chunk Overlap: 200 tokens (preserves medical context)\n",
      "Length Function: tiktoken_len (same as working notebooks)\n",
      "\n",
      "=== Document Processing ===\n",
      "Original Documents: 14\n",
      "Split Chunks: 58\n",
      "Max Chunk Length: 1199 tokens\n",
      "\n",
      "=== Vector Store Initialized ===\n",
      "Model: text-embedding-3-small\n",
      "Location: :memory:\n",
      "Documents Indexed: 58\n",
      "\n",
      "=== Retriever Ready ===\n",
      "Retriever: qdrant_retriever\n",
      "Real Medical Data: 14 documents from official sources\n"
     ]
    }
   ],
   "source": [
    "# Task 3: Real Medical Data Collection and Processing\n",
    "\n",
    "import os\n",
    "import tiktoken\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create data directory structure\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "print(\"=== Data Directory Structure Created ===\")\n",
    "print(\"data/\")\n",
    "\n",
    "# Download real medical documents from URLs (following instructor's pattern)\n",
    "print(\"=== Downloading Real Medical Documents ===\")\n",
    "\n",
    "# Mayo Clinic - Disease Information\n",
    "!curl https://www.mayoclinic.org/diseases-conditions/diabetes/symptoms-causes/syc-20371444 -o data/diabetes_guide.html\n",
    "!curl https://www.mayoclinic.org/diseases-conditions/high-blood-pressure/symptoms-causes/syc-20373410 -o data/hypertension_guide.html\n",
    "!curl https://www.mayoclinic.org/diseases-conditions/heart-disease/symptoms-causes/syc-20353118 -o data/heart_disease_guide.html\n",
    "!curl https://www.mayoclinic.org/diseases-conditions/arthritis/symptoms-causes/syc-20350772 -o data/arthritis_guide.html\n",
    "!curl https://www.mayoclinic.org/diseases-conditions/asthma/symptoms-causes/syc-20369653 -o data/asthma_guide.html\n",
    "\n",
    "# NIH MedlinePlus - Drug Information\n",
    "!curl https://medlineplus.gov/druginfo/meds/a682878.html -o data/aspirin_info.html\n",
    "!curl https://medlineplus.gov/druginfo/meds/a682159.html -o data/ibuprofen_info.html\n",
    "!curl https://medlineplus.gov/druginfo/meds/a682345.html -o data/metformin_info.html\n",
    "!curl https://medlineplus.gov/druginfo/meds/a682345.html -o data/statins_info.html\n",
    "\n",
    "# FDA Drug Safety Information\n",
    "!curl https://www.fda.gov/drugs/drug-safety-and-availability/drug-interactions -o data/drug_interactions.html\n",
    "!curl https://www.fda.gov/drugs/drug-safety-and-availability/medication-guides -o data/medication_guides.html\n",
    "\n",
    "# Lab Tests Information\n",
    "!curl https://medlineplus.gov/lab-tests/complete-blood-count-cbc/ -o data/cbc_test.html\n",
    "!curl https://medlineplus.gov/lab-tests/blood-glucose-test/ -o data/blood_glucose_test.html\n",
    "!curl https://medlineplus.gov/lab-tests/cholesterol-levels/ -o data/cholesterol_test.html\n",
    "\n",
    "print(\"✅ Real medical documents downloaded successfully!\")\n",
    "\n",
    "# Load documents using DirectoryLoader (following instructor's pattern)\n",
    "print(\"=== Loading Medical Documents ===\")\n",
    "\n",
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.html\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"✅ Loaded {len(docs)} medical documents\")\n",
    "\n",
    "# Text splitter configuration (SAME implementation as working notebooks, better medical parameters)\n",
    "def tiktoken_len(text):\n",
    "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,  # Better for medical concepts (vs 750 for loans)\n",
    "    chunk_overlap=200,  # Preserve medical context (vs 0 for loans)\n",
    "    length_function=tiktoken_len,  # SAME as working notebooks\n",
    ")\n",
    "\n",
    "print(\"\\n=== Chunking Strategy ===\")\n",
    "print(f\"Chunk Size: 1200 tokens (medical-optimized)\")\n",
    "print(f\"Chunk Overlap: 200 tokens (preserves medical context)\")\n",
    "print(f\"Length Function: tiktoken_len (same as working notebooks)\")\n",
    "\n",
    "# Split documents (SAME implementation as working notebooks)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"\\n=== Document Processing ===\")\n",
    "print(f\"Original Documents: {len(docs)}\")\n",
    "print(f\"Split Chunks: {len(split_docs)}\")\n",
    "\n",
    "# Verify max chunk length (SAME implementation as working notebooks)\n",
    "max_chunk_length = 0\n",
    "for chunk in split_docs:\n",
    "    max_chunk_length = max(max_chunk_length, tiktoken_len(chunk.page_content))\n",
    "print(f\"Max Chunk Length: {max_chunk_length} tokens\")\n",
    "\n",
    "# Initialize embeddings and vector store (SAME implementation as working notebooks)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "qdrant_vectorstore = Qdrant.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embedding_model,\n",
    "    location=\":memory:\"\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Vector Store Initialized ===\")\n",
    "print(f\"Model: text-embedding-3-small\")\n",
    "print(f\"Location: :memory:\")\n",
    "print(f\"Documents Indexed: {len(split_docs)}\")\n",
    "\n",
    "# Set up retriever (SAME implementation as working notebooks)\n",
    "qdrant_retriever = qdrant_vectorstore.as_retriever()\n",
    "\n",
    "print(f\"\\n=== Retriever Ready ===\")\n",
    "print(f\"Retriever: qdrant_retriever\")\n",
    "print(f\"Real Medical Data: {len(docs)} documents from official sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Building a Quick End-to-End Agentic RAG Prototype\n",
    "\n",
    "## End-to-End Agentic RAG Implementation\n",
    "\n",
    "This task builds a complete RAG system with agentic reasoning capabilities for the Personal Health Copilot. The system uses a single agent with multiple medical tools, following a cyclic pattern where the agent can use different tools based on the medical query type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== End-to-End Agentic RAG Prototype Ready ===\n",
      "✅ Single agent with 6 medical tools\n",
      "✅ RAG + Web Search + Research + Medical Reasoning\n",
      "✅ External API integration\n",
      "✅ Local deployment ready\n",
      "\n",
      "=== Testing Prototype ===\n",
      "\n",
      "Test 1: I have a headache and fever, what could this mean?\n",
      "Response: The combination of a headache and fever can indicate various conditions, ranging from mild to more serious issues. Common possibilities include:\n",
      "\n",
      "1. **Viral Infections**: Such as the flu or common cold.\n",
      "2. **Bacterial Infections**: Such as sinusitis or meningitis.\n",
      "3. **Dehydration**: Which can lead to headaches and fever.\n",
      "4. **Tension Headaches**: Sometimes accompanied by fever due to stress or fatigue.\n",
      "\n",
      "It's important to consult a healthcare provider for a proper diagnosis and treatment, especially if symptoms persist or worsen.\n",
      "---\n",
      "\n",
      "Test 2: I'm taking aspirin and ibuprofen, are there any interactions?\n",
      "Response: There are potential interactions between aspirin and ibuprofen. Both medications are nonsteroidal anti-inflammatory drugs (NSAIDs) and can increase the risk of gastrointestinal side effects, such as bleeding or ulcers, when taken together. It's important to consult a healthcare professional or pharmacist for personalized advice and safety information regarding your specific situation.\n",
      "---\n",
      "\n",
      "Test 3: My blood test shows elevated white blood cells, what does this mean?\n",
      "Response: Elevated white blood cell (WBC) counts can indicate several conditions, including:\n",
      "\n",
      "1. **Infection**: The body may produce more white blood cells to fight off infections.\n",
      "2. **Inflammation**: Conditions like arthritis or inflammatory diseases can lead to increased WBCs.\n",
      "3. **Stress**: Physical or emotional stress can temporarily raise WBC counts.\n",
      "4. **Allergic Reactions**: Allergies can also cause an increase in white blood cells.\n",
      "5. **Bone Marrow Disorders**: Certain conditions affecting the bone marrow can lead to elevated WBCs.\n",
      "\n",
      "It's important to consult with your healthcare provider for a complete interpretation and to understand the context of your specific situation.\n",
      "---\n",
      "\n",
      "Test 4: What are the latest treatments for diabetes?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17113/1549698894.py:68: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  search_tool = TavilySearchResults(max_results=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The latest treatments for diabetes in 2023 include several advancements and innovations:\n",
      "\n",
      "1. **iLet Bionic Pancreas**: The FDA has approved the iLet ACE Pump and iLet Dosing Decision Software, which, when used with a compatible integrated continuous glucose monitor (iCGM), forms the iLet Bionic Pancreas. This system aims to automate insulin delivery and improve glucose control.\n",
      "\n",
      "2. **Tirzepatide (Mounjaro)**: This medication, initially approved for diabetes management, is also marketed as Zepbound for weight loss. It has shown promise in managing blood sugar levels and aiding in weight loss for individuals with type 2 diabetes.\n",
      "\n",
      "3. **Teplizumab**: Approved in late 2022, this drug is used to delay the onset of type 1 diabetes, representing a significant breakthrough in diabetes prevention.\n",
      "\n",
      "4. **Biosimilars for Insulin**: New biosimilars, such as Admelog (insulin lispro), have been approved, providing more affordable options for insulin therapy, which is crucial for many diabetes patients.\n",
      "\n",
      "5. **Wearable and Implantable Devices**: Innovations in technology have led to the development of wearable and implantable devices that facilitate insulin release, offering greater convenience and improved management of diabetes.\n",
      "\n",
      "6. **Research into Cures**: Ongoing research is exploring potential treatments like beta cell transplantation, immunotherapy, and regenerative medicine, which may lead to future cures for diabetes.\n",
      "\n",
      "These advancements reflect a growing focus on personalized treatment options, improved management tools, and the potential for preventive therapies in diabetes care. For more detailed information, you can refer to the sources from Healthline and News-Medical.\n",
      "---\n",
      "\n",
      "Test 5: Search for recent research on COVID-19 long-term effects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17113/1549698894.py:92: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Here are some recent research papers related to the long-term effects of COVID-19:\n",
      "\n",
      "1. **Ultrasound Diagnosis of COVID-19: Robustness and Explainability**\n",
      "   - **Authors**: Jay Roberts, Theodoros Tsiligkaridis\n",
      "   - **Abstract**: This study focuses on the importance of point-of-care ultrasound (POCUS) in diagnosing COVID-19, providing rapid imagery of lungs to detect the disease in a cost-effective manner.\n",
      "   - **URL**: [Read more](http://arxiv.org/abs/2012.01145v1)\n",
      "\n",
      "2. **A model for the outbreak of COVID-19: Vaccine effectiveness in a case study of Italy**\n",
      "   - **Authors**: Vasiliki Bitsouni, Nikolaos Gialelis, Ioannis G. Stratis\n",
      "   - **Abstract**: This paper presents a mathematical model for the spread of COVID-19, considering asymptomatic individuals and analyzing vaccine effectiveness.\n",
      "   - **URL**: [Read more](http://arxiv.org/abs/2008.00828v2)\n",
      "\n",
      "3. **COVID-19: Comparative Analysis of Methods for Identifying Articles Related to Therapeutics and Vaccines without Using Labeled Data**\n",
      "   - **Authors**: Mihir Parmar, Ashwin Karthik Ambalavanan, Hong Guan, Rishab Banerjee, Jitesh Pabla, Murthy Devarakonda\n",
      "   - **Abstract**: This research proposes an approach to analyze text classification methods for screening articles relevant to COVID-19 therapeutics and vaccines.\n",
      "   - **URL**: [Read more](http://arxiv.org/abs/2101.02017v1)\n",
      "\n",
      "These papers may provide insights into various aspects of COVID-19, including its long-term effects and related research methodologies.\n",
      "---\n",
      "\n",
      "✅ End-to-End Agentic RAG Prototype Complete\n",
      "✅ Local deployment: compiled_health_graph.invoke()\n"
     ]
    }
   ],
   "source": [
    "# Task 4: End-to-End Agentic RAG Prototype\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define state for our agent\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ===== RAG CHAIN SETUP =====\n",
    "# RAG TEMPLATE - This is where AUGMENTATION happens\n",
    "# The {context} placeholder gets filled with retrieved documents\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and knowledgeable medical assistant. Use the context provided below to answer the medical question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}  # ← AUGMENTATION: Retrieved medical documents are inserted here\n",
    "\"\"\"\n",
    "\n",
    "# Create prompt template for RAG\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "# ===== RAG CHAIN CREATION =====\n",
    "# This chain combines RETRIEVAL, AUGMENTATION, and GENERATION\n",
    "rag_chain = (\n",
    "    # RETRIEVAL: qdrant_retriever gets relevant medical documents\n",
    "    {\"context\": itemgetter(\"question\") | qdrant_retriever, \"question\": itemgetter(\"question\")}\n",
    "    # AUGMENTATION: Documents are inserted into prompt template as {context}\n",
    "    | rag_prompt \n",
    "    # GENERATION: LLM generates answer using the augmented context\n",
    "    | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ===== MEDICAL TOOLS =====\n",
    "@tool\n",
    "def retrieve_medical_information(\n",
    "    query: Annotated[str, \"Medical query to search for information about symptoms, treatments, or health conditions\"]\n",
    "):\n",
    "    \"\"\"Use RAG to retrieve medical information from verified sources\"\"\"\n",
    "    # This tool executes the complete RAG pipeline:\n",
    "    # RETRIEVAL → AUGMENTATION → GENERATION\n",
    "    return rag_chain.invoke({\"question\": query})\n",
    "\n",
    "@tool\n",
    "def web_search_medical_info(\n",
    "    query: Annotated[str, \"Medical query to search the web for current health information, treatments, or medical research\"]\n",
    "):\n",
    "    \"\"\"Search the web for current medical information, treatments, and health research\"\"\"\n",
    "    from langchain_community.tools import TavilySearchResults\n",
    "    \n",
    "    search_tool = TavilySearchResults(max_results=3)\n",
    "    results = search_tool.invoke(query)\n",
    "    \n",
    "    # Format the search results\n",
    "    formatted_results = []\n",
    "    for result in results:\n",
    "        formatted_results.append(f\"Title: {result['title']}\\nURL: {result['url']}\\nContent: {result['content']}\\n\")\n",
    "    \n",
    "    return f\"Web search results for '{query}':\\n\" + \"\\n\".join(formatted_results)\n",
    "\n",
    "@tool\n",
    "def search_medical_research(\n",
    "    query: Annotated[str, \"Medical research query to search ArXiv for scientific papers and studies\"]\n",
    "):\n",
    "    \"\"\"Search ArXiv for medical research papers and scientific studies\"\"\"\n",
    "    import arxiv\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=3,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for result in search.results():\n",
    "        results.append(f\"Title: {result.title}\\nAuthors: {', '.join([author.name for author in result.authors])}\\nAbstract: {result.summary[:300]}...\\nURL: {result.entry_id}\\n\")\n",
    "    \n",
    "    return f\"Medical research results for '{query}':\\n\" + \"\\n\".join(results)\n",
    "\n",
    "@tool\n",
    "def analyze_symptoms(\n",
    "    symptoms: Annotated[str, \"List of symptoms to analyze for possible conditions\"]\n",
    "):\n",
    "    \"\"\"Analyze symptoms and suggest possible conditions based on medical knowledge\"\"\"\n",
    "    return f\"Based on symptoms: {symptoms}, I recommend consulting a healthcare provider for proper diagnosis.\"\n",
    "\n",
    "@tool\n",
    "def check_drug_interactions(\n",
    "    medications: Annotated[str, \"List of current medications to check for potential interactions\"]\n",
    "):\n",
    "    \"\"\"Check for potential drug interactions with current medications\"\"\"\n",
    "    return f\"Checking interactions for medications: {medications}. Please consult a pharmacist for complete safety information.\"\n",
    "\n",
    "@tool\n",
    "def interpret_lab_results(\n",
    "    lab_results: Annotated[str, \"Lab test results to interpret and explain\"]\n",
    "):\n",
    "    \"\"\"Interpret lab test results and explain what they mean in plain language\"\"\"\n",
    "    return f\"Interpreting lab results: {lab_results}. Please consult with your healthcare provider for complete medical interpretation.\"\n",
    "\n",
    "# ===== AGENT SETUP =====\n",
    "# Bind tools to model\n",
    "tool_belt = [retrieve_medical_information, web_search_medical_info, search_medical_research, analyze_symptoms, check_drug_interactions, interpret_lab_results]\n",
    "llm = llm.bind_tools(tool_belt)\n",
    "\n",
    "# Create nodes\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tool_node = ToolNode(tool_belt)\n",
    "\n",
    "# ===== GRAPH BUILDING =====\n",
    "# Build graph\n",
    "health_graph = StateGraph(AgentState)\n",
    "health_graph.add_node(\"agent\", call_model)\n",
    "health_graph.add_node(\"action\", tool_node)\n",
    "health_graph.set_entry_point(\"agent\")\n",
    "\n",
    "# Conditional edges\n",
    "def should_continue(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"action\"\n",
    "    return END\n",
    "\n",
    "health_graph.add_conditional_edges(\"agent\", should_continue)\n",
    "health_graph.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Compile graph\n",
    "compiled_health_graph = health_graph.compile()\n",
    "\n",
    "print(\"=== End-to-End Agentic RAG Prototype Ready ===\")\n",
    "print(\"✅ Single agent with 6 medical tools\")\n",
    "print(\"✅ RAG + Web Search + Research + Medical Reasoning\")\n",
    "print(\"✅ External API integration\")\n",
    "print(\"✅ Local deployment ready\")\n",
    "\n",
    "# ===== TESTING =====\n",
    "# Test the prototype\n",
    "test_queries = [\n",
    "    \"I have a headache and fever, what could this mean?\",\n",
    "    \"I'm taking aspirin and ibuprofen, are there any interactions?\",\n",
    "    \"My blood test shows elevated white blood cells, what does this mean?\",\n",
    "    \"What are the latest treatments for diabetes?\",\n",
    "    \"Search for recent research on COVID-19 long-term effects\"\n",
    "]\n",
    "\n",
    "print(f\"\\n=== Testing Prototype ===\")\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nTest {i}: {query}\")\n",
    "    test_input = {\"messages\": [HumanMessage(content=query)]}\n",
    "    \n",
    "    # Get final response\n",
    "    final_response = compiled_health_graph.invoke(test_input)\n",
    "    final_message = final_response[\"messages\"][-1]\n",
    "    \n",
    "    print(f\"Response: {final_message.content}\")\n",
    "    print(\"---\")\n",
    "\n",
    "print(f\"\\n✅ End-to-End Agentic RAG Prototype Complete\")\n",
    "print(f\"✅ Local deployment: compiled_health_graph.invoke()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Medical Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Symptom Analysis ===\n",
      "Query: I have a headache and fever, what could this mean?\n",
      "Response: The combination of a headache and fever can indicate various conditions, ranging from mild to more serious issues. Common possibilities include:\n",
      "\n",
      "1. **Viral Infections**: Such as the flu or common cold.\n",
      "2. **Bacterial Infections**: Such as sinusitis or meningitis.\n",
      "3. **Dehydration**: Which can lead to headaches and fever.\n",
      "4. **Other Conditions**: Such as tension headaches or migraines, which can sometimes be accompanied by fever.\n",
      "\n",
      "It's important to consult a healthcare provider for a proper diagnosis and treatment, especially if symptoms persist or worsen.\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Medical symptom query\n",
    "test_input_1 = {\"messages\": [HumanMessage(content=\"I have a headache and fever, what could this mean?\")]}\n",
    "response_1 = compiled_health_graph.invoke(test_input_1)\n",
    "print(\"=== Test 1: Symptom Analysis ===\")\n",
    "print(f\"Query: I have a headache and fever, what could this mean?\")\n",
    "print(f\"Response: {response_1['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Drug Interaction Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 2: Drug Interaction Check ===\n",
      "Query: I'm taking aspirin and ibuprofen, are there any interactions?\n",
      "Response: There are potential interactions between aspirin and ibuprofen. Both medications are nonsteroidal anti-inflammatory drugs (NSAIDs) and can increase the risk of gastrointestinal side effects, such as ulcers and bleeding, when taken together. It's important to consult a healthcare professional or pharmacist for personalized advice and safety information regarding your specific situation.\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Drug interaction query\n",
    "test_input_2 = {\"messages\": [HumanMessage(content=\"I'm taking aspirin and ibuprofen, are there any interactions?\")]}\n",
    "response_2 = compiled_health_graph.invoke(test_input_2)\n",
    "print(\"=== Test 2: Drug Interaction Check ===\")\n",
    "print(f\"Query: I'm taking aspirin and ibuprofen, are there any interactions?\")\n",
    "print(f\"Response: {response_2['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Lab Results Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 3: Lab Results Interpretation ===\n",
      "Query: My blood test shows elevated white blood cells, what does this mean?\n",
      "Response: Elevated white blood cell (WBC) counts can indicate several conditions, including:\n",
      "\n",
      "1. **Infection**: The body may produce more white blood cells to fight off infections.\n",
      "2. **Inflammation**: Conditions that cause inflammation, such as autoimmune diseases, can lead to increased WBC counts.\n",
      "3. **Stress**: Physical or emotional stress can temporarily raise white blood cell levels.\n",
      "4. **Allergic Reactions**: Allergies can also cause an increase in white blood cells.\n",
      "5. **Bone Marrow Disorders**: Certain conditions affecting the bone marrow can lead to elevated WBC counts.\n",
      "\n",
      "It's important to consult with your healthcare provider for a complete interpretation of your lab results and to understand the underlying cause of the elevated white blood cell count.\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Lab results query\n",
    "test_input_3 = {\"messages\": [HumanMessage(content=\"My blood test shows elevated white blood cells, what does this mean?\")]}\n",
    "response_3 = compiled_health_graph.invoke(test_input_3)\n",
    "print(\"=== Test 3: Lab Results Interpretation ===\")\n",
    "print(f\"Query: My blood test shows elevated white blood cells, what does this mean?\")\n",
    "print(f\"Response: {response_3['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 4: Web Search Medical Info ===\n",
      "Query: What are the latest treatments for diabetes?\n",
      "Response: The latest treatments for diabetes in 2023 include several advancements and innovations:\n",
      "\n",
      "1. **iLet Bionic Pancreas**: The FDA has approved the iLet ACE Pump and iLet Dosing Decision Software, which, when used with a compatible integrated continuous glucose monitor (iCGM), forms the iLet Bionic Pancreas. This system aims to automate insulin delivery and improve glucose control.\n",
      "\n",
      "2. **Tirzepatide (Mounjaro/Zepbound)**: This medication has been approved for diabetes management and is also being marketed for weight loss. It represents a significant advancement in diabetes treatment, particularly for patients with obesity.\n",
      "\n",
      "3. **Teplizumab**: Approved in late 2022, this drug is used to delay the onset of type 1 diabetes, marking a breakthrough in the prevention of this condition.\n",
      "\n",
      "4. **Biosimilars for Insulin**: New biosimilars, such as Admelog (insulin lispro), have been approved, providing more affordable options for insulin therapy, which is crucial for many diabetes patients.\n",
      "\n",
      "5. **Wearable and Implantable Devices**: Innovations in technology have led to the development of devices that can release insulin automatically, enhancing convenience and control for individuals managing diabetes.\n",
      "\n",
      "6. **Research into Cures**: Ongoing research is exploring potential treatments like beta cell transplantation, immunotherapy, and regenerative medicine, which hold promise for future diabetes cures.\n",
      "\n",
      "These advancements reflect a growing focus on personalized treatment options, weight management, and the integration of technology in diabetes care. For more detailed information, you can refer to the [American Diabetes Association's 2023 Standards of Care](https://diabetes.org/newsroom/american-diabetes-association-2023-standards-care-diabetes-guide-for-prevention-diagnosis-treatment-people-living-with-diabetes).\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Web search query\n",
    "test_input_4 = {\"messages\": [HumanMessage(content=\"What are the latest treatments for diabetes?\")]}\n",
    "response_4 = compiled_health_graph.invoke(test_input_4)\n",
    "print(\"=== Test 4: Web Search Medical Info ===\")\n",
    "print(f\"Query: What are the latest treatments for diabetes?\")\n",
    "print(f\"Response: {response_4['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17113/1549698894.py:92: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 5: Medical Research Search ===\n",
      "Query: Search for recent research on COVID-19 long-term effects\n",
      "Response: Here are some recent research papers related to the long-term effects of COVID-19:\n",
      "\n",
      "1. **Ultrasound Diagnosis of COVID-19: Robustness and Explainability**\n",
      "   - **Authors**: Jay Roberts, Theodoros Tsiligkaridis\n",
      "   - **Abstract**: This study discusses the importance of point of care ultrasound (POCUS) in diagnosing COVID-19, providing rapid imagery of lungs to detect the disease in a cost-effective manner.\n",
      "   - **URL**: [Read more](http://arxiv.org/abs/2012.01145v1)\n",
      "\n",
      "2. **A model for the outbreak of COVID-19: Vaccine effectiveness in a case study of Italy**\n",
      "   - **Authors**: Vasiliki Bitsouni, Nikolaos Gialelis, Ioannis G. Stratis\n",
      "   - **Abstract**: This paper presents a mathematical model for the spread of COVID-19, considering asymptomatic individuals and analyzing the effectiveness of vaccines.\n",
      "   - **URL**: [Read more](http://arxiv.org/abs/2008.00828v2)\n",
      "\n",
      "3. **COVID-19: Comparative Analysis of Methods for Identifying Articles Related to Therapeutics and Vaccines without Using Labeled Data**\n",
      "   - **Authors**: Mihir Parmar, Ashwin Karthik Ambalavanan, Hong Guan, Rishab Banerjee, Jitesh Pabla, Murthy Devarakonda\n",
      "   - **Abstract**: This research proposes an approach to analyze text classification methods for screening articles relevant to COVID-19 therapeutics and vaccines.\n",
      "   - **URL**: [Read more](http://arxiv.org/abs/2101.02017v1)\n",
      "\n",
      "These papers may provide insights into various aspects of COVID-19, including its long-term effects and related research methodologies.\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Medical research query\n",
    "test_input_5 = {\"messages\": [HumanMessage(content=\"Search for recent research on COVID-19 long-term effects\")]}\n",
    "response_5 = compiled_health_graph.invoke(test_input_5)\n",
    "print(\"=== Test 5: Medical Research Search ===\")\n",
    "print(f\"Query: Search for recent research on COVID-19 long-term effects\")\n",
    "print(f\"Response: {response_5['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17113/1549698894.py:92: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 6: Combined Tools Query ===\n",
      "Query: What are the current guidelines for blood pressure management and any recent research on this topic?\n",
      "Response: ### Current Guidelines for Blood Pressure Management\n",
      "\n",
      "The current guidelines for blood pressure management, as outlined by the American College of Cardiology and the American Heart Association, categorize blood pressure into four general categories:\n",
      "\n",
      "1. **Normal blood pressure**: Less than 120/80 mm Hg.\n",
      "2. **Elevated blood pressure**: Systolic (top number) between 120-129 mm Hg and diastolic (bottom number) less than 80 mm Hg.\n",
      "3. **Stage 1 hypertension**: Systolic between 130-139 mm Hg or diastolic between 80-89 mm Hg.\n",
      "4. **Stage 2 hypertension**: Systolic 140 mm Hg or higher or diastolic 90 mm Hg or higher.\n",
      "\n",
      "A blood pressure reading higher than 180/120 mm Hg is considered a hypertensive emergency, requiring immediate medical attention.\n",
      "\n",
      "**Management Strategies**:\n",
      "- **Lifestyle Modifications**: Maintaining a healthy diet, regular physical activity, avoiding tobacco, and managing stress.\n",
      "- **Medications**: Some individuals may require medication to control their blood pressure effectively.\n",
      "- **Monitoring**: Regular monitoring of blood pressure is recommended, with checks at least every two years starting at age 18, and more frequently for those at higher risk.\n",
      "\n",
      "### Recent Research on Blood Pressure Management\n",
      "\n",
      "1. **Title**: [Can't Take the Pressure? Examining the Challenges of Blood Pressure Estimation via Pulse Wave Analysis](http://arxiv.org/abs/2304.14916v1)\n",
      "   - **Authors**: Suril Mehta, Nipun Kwatra, Mohit Jain, Daniel McDuff\n",
      "   - **Abstract**: This research explores the use of wearable sensor data (e.g., photoplethysmograms [PPG]) to infer health measures like blood pressure. The technology has significant implications for health screening, chronic disease management, and remote monitoring.\n",
      "\n",
      "2. **Title**: [Constructing optimal dynamic monitoring and treatment regimes: An application to hypertension care](http://arxiv.org/abs/2501.08274v1)\n",
      "   - **Authors**: Janie Coulombe, Dany El-Riachi, Fanxing Du, Tianze Jiao\n",
      "   - **Abstract**: This study addresses hypertension as a leading cause of cardiovascular diseases and examines the heterogeneous effects of antihypertensive drugs and management strategies, aiming to construct optimal dynamic treatment regimes for hypertension.\n",
      "\n",
      "3. **Title**: [Developing Personalized Models of Blood Pressure Estimation from Wearable Sensors Data Using Minimally-trained Domain Adversarial Neural Networks](http://arxiv.org/abs/2007.12802v1)\n",
      "   - **Authors**: Lida Zhang, Nathan C. Hurley, Bassem Ibrahim, Erica Spatz, Harlan M. Krumholz, Roozbeh Jafari, Bobak J. Mortazavi\n",
      "   - **Abstract**: This research focuses on blood pressure monitoring as a crucial component of hypertension management and the prediction of associated comorbidities, emphasizing the need for capturing blood pressure remotely and frequently.\n",
      "\n",
      "These guidelines and research findings highlight the importance of both lifestyle changes and technological advancements in managing blood pressure effectively.\n"
     ]
    }
   ],
   "source": [
    "# Test 6: Combined query (uses multiple tools)\n",
    "test_input_6 = {\"messages\": [HumanMessage(content=\"What are the current guidelines for blood pressure management and any recent research on this topic?\")]}\n",
    "response_6 = compiled_health_graph.invoke(test_input_6)\n",
    "print(\"=== Test 6: Combined Tools Query ===\")\n",
    "print(f\"Query: What are the current guidelines for blood pressure management and any recent research on this topic?\")\n",
    "print(f\"Response: {response_6['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Creating a Golden Test Data Set\n",
    "\n",
    "## Dataset creation and RAGAS Evaluation Setup\n",
    "\n",
    "This task will create a synthetic test dataset and evaluate our Personal Health Copilot using RAGAS metrics to assess pipeline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/saimo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/saimo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK packages downloaded!\n",
      "Ragas components imported!\n",
      "Ready for evaluation!\n",
      "Step 1: Creating Golden Dataset for Medical Queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781e1070f34f45aa817156d4abefee27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7b2c57dbf34ae09006436f827337a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999b071d1bc44a34bb3055d67e29e9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node 'd0d948'. Skipping!\n",
      "Property 'summary' already exists in node '7aac3d'. Skipping!\n",
      "Property 'summary' already exists in node '3900ad'. Skipping!\n",
      "Property 'summary' already exists in node 'c123ad'. Skipping!\n",
      "Property 'summary' already exists in node '3fa995'. Skipping!\n",
      "Property 'summary' already exists in node 'bb6c9e'. Skipping!\n",
      "Property 'summary' already exists in node 'a70363'. Skipping!\n",
      "Property 'summary' already exists in node 'b70a13'. Skipping!\n",
      "Property 'summary' already exists in node '4895b1'. Skipping!\n",
      "Property 'summary' already exists in node 'c37262'. Skipping!\n",
      "Property 'summary' already exists in node 'c9f8dd'. Skipping!\n",
      "Property 'summary' already exists in node '3cc052'. Skipping!\n",
      "Property 'summary' already exists in node '6f63e6'. Skipping!\n",
      "Property 'summary' already exists in node 'fc4e81'. Skipping!\n",
      "Property 'summary' already exists in node '865e97'. Skipping!\n",
      "Property 'summary' already exists in node '4e422f'. Skipping!\n",
      "Property 'summary' already exists in node 'efdbd3'. Skipping!\n",
      "Property 'summary' already exists in node '19bba5'. Skipping!\n",
      "Property 'summary' already exists in node '38e393'. Skipping!\n",
      "Property 'summary' already exists in node '7ce67b'. Skipping!\n",
      "Property 'summary' already exists in node 'edf40b'. Skipping!\n",
      "Property 'summary' already exists in node 'df8d66'. Skipping!\n",
      "Property 'summary' already exists in node '63f015'. Skipping!\n",
      "Property 'summary' already exists in node 'e59eda'. Skipping!\n",
      "Property 'summary' already exists in node '206e38'. Skipping!\n",
      "Property 'summary' already exists in node '92f358'. Skipping!\n",
      "Property 'summary' already exists in node '5e1afe'. Skipping!\n",
      "Property 'summary' already exists in node '095641'. Skipping!\n",
      "Property 'summary' already exists in node 'af99e5'. Skipping!\n",
      "Property 'summary' already exists in node '413530'. Skipping!\n",
      "Property 'summary' already exists in node '2aae72'. Skipping!\n",
      "Property 'summary' already exists in node 'abf56e'. Skipping!\n",
      "Property 'summary' already exists in node '7cbd3b'. Skipping!\n",
      "Property 'summary' already exists in node '93ebe8'. Skipping!\n",
      "Property 'summary' already exists in node 'b3bf0e'. Skipping!\n",
      "Property 'summary' already exists in node '704e82'. Skipping!\n",
      "Property 'summary' already exists in node '792794'. Skipping!\n",
      "Property 'summary' already exists in node '36faf8'. Skipping!\n",
      "Property 'summary' already exists in node 'ab756b'. Skipping!\n",
      "Property 'summary' already exists in node '891840'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f27077b8114080a4dc9cb172ec14e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c63509b5414ac28bfe23e40028a242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node 'c123ad'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3900ad'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7aac3d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'bb6c9e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3fa995'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd0d948'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a70363'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c37262'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c9f8dd'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fc4e81'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '19bba5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '5e1afe'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b70a13'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4895b1'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6f63e6'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3cc052'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '92f358'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '63f015'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '865e97'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4e422f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7ce67b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '38e393'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '095641'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'efdbd3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e59eda'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'df8d66'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'edf40b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '206e38'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'af99e5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '413530'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b3bf0e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '891840'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '93ebe8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'abf56e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2aae72'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7cbd3b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ab756b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '792794'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '36faf8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '704e82'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7439959af947476788b61404fcc5c8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95443909a4bb45af8b89ed49aa93bc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6f26bf52604fcfb0265c2ecc318307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0636cda83c4fa6980fe3d43c5a91dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created synthetic dataset with 6 test cases\n",
      "Golden dataset created successfully using REAL medical data ONLY!\n",
      "\n",
      "=== Golden Dataset Display ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What precautions should I take if I am allergi...</td>\n",
       "      <td>[What special dietary instructions should I fo...</td>\n",
       "      <td>Before taking metolazone, tell your doctor and...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What kind of foods like orange juice should I ...</td>\n",
       "      <td>[plan to avoid unnecessary or prolonged exposu...</td>\n",
       "      <td>You should include increased amounts of potass...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What special dietary instructions should I fol...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDo not give nonprescription ibupro...</td>\n",
       "      <td>Unless your doctor tells you otherwise, you sh...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the complications associated with hig...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nRequest an appointment From Mayo C...</td>\n",
       "      <td>The complications associated with high blood p...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What precautions should be taken when administ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDo not give nonprescription ibupro...</td>\n",
       "      <td>When administering ibuprofen to a child, it is...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What dietary instructions should be followed w...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nWhat special dietary instructions ...</td>\n",
       "      <td>While taking metolazone, a diuretic, it is imp...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What precautions should I take if I am allergi...   \n",
       "1  What kind of foods like orange juice should I ...   \n",
       "2  What special dietary instructions should I fol...   \n",
       "3  What are the complications associated with hig...   \n",
       "4  What precautions should be taken when administ...   \n",
       "5  What dietary instructions should be followed w...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [What special dietary instructions should I fo...   \n",
       "1  [plan to avoid unnecessary or prolonged exposu...   \n",
       "2  [<1-hop>\\n\\nDo not give nonprescription ibupro...   \n",
       "3  [<1-hop>\\n\\nRequest an appointment From Mayo C...   \n",
       "4  [<1-hop>\\n\\nDo not give nonprescription ibupro...   \n",
       "5  [<1-hop>\\n\\nWhat special dietary instructions ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Before taking metolazone, tell your doctor and...   \n",
       "1  You should include increased amounts of potass...   \n",
       "2  Unless your doctor tells you otherwise, you sh...   \n",
       "3  The complications associated with high blood p...   \n",
       "4  When administering ibuprofen to a child, it is...   \n",
       "5  While taking metolazone, a diuretic, it is imp...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  multi_hop_abstract_query_synthesizer  \n",
       "3  multi_hop_abstract_query_synthesizer  \n",
       "4  multi_hop_specific_query_synthesizer  \n",
       "5  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 5: Creating a Golden Test Data Set - Part 1: Dataset Creation\n",
    "\n",
    "# NLTK Setup (required for Ragas)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Ragas Imports\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas import evaluate, EvaluationDataset\n",
    "from ragas.metrics import (\n",
    "    ContextRecall,           # Traditional - Medical database coverage\n",
    "    LLMContextRecall,        # Response coverage of retrieved medical info\n",
    "    ContextEntityRecall,     # Medical entity recognition\n",
    "    ContextPrecision,        # Medical information relevance\n",
    "    Faithfulness,            # Medical accuracy adherence\n",
    "    FactualCorrectness,      # Medical fact verification\n",
    "    ResponseRelevancy,       # Medical query-response alignment\n",
    "    NoiseSensitivity         # Medical information filtering\n",
    ")\n",
    "from ragas import RunConfig\n",
    "\n",
    "print(\"NLTK packages downloaded!\")\n",
    "print(\"Ragas components imported!\")\n",
    "print(\"Ready for evaluation!\")\n",
    "\n",
    "# Task 5: Golden Dataset Creation (Using Real Medical Data Only)\n",
    "\n",
    "print(\"Step 1: Creating Golden Dataset for Medical Queries...\")\n",
    "\n",
    "# Verify we have real medical data from Task 3\n",
    "if len(split_docs) == 0 or max_chunk_length < 500:\n",
    "    raise ValueError(\"CRITICAL ERROR: No real medical data available for golden dataset creation.\")\n",
    "\n",
    "# Setup LLM and embeddings (exactly as in working notebook)\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "# Create synthetic dataset with 5 test cases using REAL medical data ONLY\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "ragas_dataset = generator.generate_with_langchain_docs(split_docs, testset_size=5)\n",
    "\n",
    "print(f\"Created synthetic dataset with {len(ragas_dataset)} test cases\")\n",
    "print(\"Golden dataset created successfully using REAL medical data ONLY!\")\n",
    "\n",
    "# Display golden dataset (exactly as in working notebook)\n",
    "print(\"\\n=== Golden Dataset Display ===\")\n",
    "ragas_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Starting RAGAS Evaluation...\n",
      "Setup complete! Ready for medical assistant evaluation.\n",
      "Evaluating Personal Health Copilot...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7304c3d30cc5427eb4a446e0c6e14d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas Evaluation Results for Personal Health Copilot:\n",
      "{'context_recall': 1.0000, 'context_precision': 0.9444, 'faithfulness': 0.9150, 'factual_correctness': 0.5683, 'answer_relevancy': 0.7891, 'context_entity_recall': 0.3338, 'noise_sensitivity_relevant': 0.3124}\n",
      "Personal Health Copilot evaluation complete\n"
     ]
    }
   ],
   "source": [
    "# Task 5: Creating a Golden Test Data Set - Part 2: RAGAS Evaluation\n",
    "\n",
    "print(\"Step 2: Starting RAGAS Evaluation...\")\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "\n",
    "# Core RAGAS metrics - ALL 8 METRICS (CORRECTED based on Advanced_Retrieval notebook)\n",
    "ragas_metrics = [\n",
    "    ContextRecall(),                        # ✅ Traditional - Medical database coverage\n",
    "    ContextPrecision(llm=evaluator_llm),   # ✅ Medical information relevance\n",
    "    LLMContextRecall(),                     # ✅ Response coverage of retrieved medical info\n",
    "    Faithfulness(),                         # ✅ Medical accuracy adherence\n",
    "    FactualCorrectness(),                   # ✅ Medical fact verification\n",
    "    ResponseRelevancy(),                    # ✅ Medical query-response alignment\n",
    "    ContextEntityRecall(),                  # ✅ Medical entity recognition\n",
    "    NoiseSensitivity()                      # ✅ Medical information filtering\n",
    "]\n",
    "\n",
    "custom_run_config = RunConfig(timeout=300)\n",
    "\n",
    "# Fixed: Use correct variable names from Task 4\n",
    "def create_evaluation_chain(retriever, name):\n",
    "    # Use rag_prompt and llm from Task 4 (these are the actual variables we have)\n",
    "    return (\n",
    "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "        | rag_prompt | llm | StrOutputParser()\n",
    "    )\n",
    "\n",
    "print(\"Setup complete! Ready for medical assistant evaluation.\")\n",
    "\n",
    "# Task 5: Medical Assistant Evaluation\n",
    "\n",
    "print(\"Evaluating Personal Health Copilot...\")\n",
    "\n",
    "eval_chain = create_evaluation_chain(qdrant_retriever, \"medical_assistant\")\n",
    "\n",
    "# Process test data for RAGAS evaluation\n",
    "for test_row in ragas_dataset:\n",
    "    response = eval_chain.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response\n",
    "    test_row.eval_sample.retrieved_contexts = [doc.page_content for doc in qdrant_retriever.invoke(test_row.eval_sample.user_input)]\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_pandas(ragas_dataset.to_pandas())\n",
    "\n",
    "from ragas import evaluate as ragas_evaluate\n",
    "\n",
    "custom_run_config = RunConfig(timeout=300)\n",
    "\n",
    "ragas_result = ragas_evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=ragas_metrics,\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config\n",
    ")\n",
    "\n",
    "print(\"Ragas Evaluation Results for Personal Health Copilot:\")\n",
    "print(ragas_result)\n",
    "\n",
    "print(\"Personal Health Copilot evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 6 : Advanced Retrievers implementation for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 6: Advanced Retrieval Techniques ===\n",
      "1. Implementing BM25 Retriever for Medical Terminology...\n",
      "✅ BM25 Retriever created with 58 medical documents\n",
      "✅ BM25 is perfect for exact medical terminology matching\n",
      "\n",
      "2. Implementing Contextual Compression with Cohere Reranking...\n",
      "✅ Contextual Compression Retriever created with Cohere reranking\n",
      "✅ Filters irrelevant medical information for better accuracy\n",
      "\n",
      "3. Creating RAG Chains for Advanced Retrievers...\n",
      "✅ RAG chains created for both advanced retrievers\n",
      "\n",
      "4. Testing Advanced Retrieval Techniques...\n",
      "\n",
      "=== Performance Comparison ===\n",
      "\n",
      "Query: What are the side effects of aspirin?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17113/3878572871.py:73: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  original_docs = qdrant_retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 4 docs retrieved\n",
      "BM25: 4 docs retrieved\n",
      "Contextual Compression: 3 docs retrieved\n",
      "\n",
      "Query: How to manage diabetes symptoms?\n",
      "Original: 4 docs retrieved\n",
      "BM25: 4 docs retrieved\n",
      "Contextual Compression: 3 docs retrieved\n",
      "\n",
      "Query: What causes high blood pressure?\n",
      "Original: 4 docs retrieved\n",
      "BM25: 4 docs retrieved\n",
      "Contextual Compression: 3 docs retrieved\n",
      "\n",
      "Query: Drug interactions with metformin\n",
      "Original: 4 docs retrieved\n",
      "BM25: 4 docs retrieved\n",
      "Contextual Compression: 3 docs retrieved\n",
      "\n",
      "✅ Advanced retrieval techniques tested successfully!\n",
      "✅ BM25 provides keyword-based medical information retrieval\n",
      "✅ Contextual Compression filters irrelevant medical information\n",
      "✅ Both techniques ready for RAGAS evaluation comparison\n"
     ]
    }
   ],
   "source": [
    "# Task 6: The Benefits of Advanced Retrieval\n",
    "\n",
    "print(\"=== Task 6: Advanced Retrieval Techniques ===\")\n",
    "\n",
    "# Advanced Retrieval Imports (same as Advanced_Retrieval notebook)\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "\n",
    "# ===== 1. BM25 Retriever Implementation (same as Advanced_Retrieval notebook) =====\n",
    "\n",
    "print(\"1. Implementing BM25 Retriever for Medical Terminology...\")\n",
    "\n",
    "# Create BM25 retriever from our medical documents (exact same pattern)\n",
    "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "\n",
    "print(f\"✅ BM25 Retriever created with {len(split_docs)} medical documents\")\n",
    "print(\"✅ BM25 is perfect for exact medical terminology matching\")\n",
    "\n",
    "# ===== 2. Contextual Compression with Cohere Reranking (same as Advanced_Retrieval notebook) =====\n",
    "\n",
    "print(\"\\n2. Implementing Contextual Compression with Cohere Reranking...\")\n",
    "\n",
    "# Create Cohere reranker (exact same pattern as Advanced_Retrieval notebook)\n",
    "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "\n",
    "# Create contextual compression retriever (exact same pattern)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=qdrant_retriever\n",
    ")\n",
    "\n",
    "print(f\"✅ Contextual Compression Retriever created with Cohere reranking\")\n",
    "print(\"✅ Filters irrelevant medical information for better accuracy\")\n",
    "\n",
    "# ===== 3. Create RAG Chains (same pattern as Advanced_Retrieval notebook) =====\n",
    "\n",
    "print(\"\\n3. Creating RAG Chains for Advanced Retrievers...\")\n",
    "\n",
    "# BM25 RAG Chain (same pattern as Advanced_Retrieval notebook)\n",
    "bm25_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "# Contextual Compression RAG Chain (same pattern as Advanced_Retrieval notebook)\n",
    "compression_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "print(\"✅ RAG chains created for both advanced retrievers\")\n",
    "\n",
    "# ===== 4. Testing Advanced Retrieval Techniques =====\n",
    "\n",
    "print(\"\\n4. Testing Advanced Retrieval Techniques...\")\n",
    "\n",
    "test_medical_queries = [\n",
    "    \"What are the side effects of aspirin?\",\n",
    "    \"How to manage diabetes symptoms?\",\n",
    "    \"What causes high blood pressure?\",\n",
    "    \"Drug interactions with metformin\"\n",
    "]\n",
    "\n",
    "print(\"\\n=== Performance Comparison ===\")\n",
    "\n",
    "for query in test_medical_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    \n",
    "    # Test original Qdrant retriever (using direct retriever)\n",
    "    original_docs = qdrant_retriever.get_relevant_documents(query)\n",
    "    print(f\"Original: {len(original_docs)} docs retrieved\")\n",
    "    \n",
    "    # Test BM25 retriever\n",
    "    bm25_response = bm25_retrieval_chain.invoke({\"question\": query})\n",
    "    print(f\"BM25: {len(bm25_response['context'])} docs retrieved\")\n",
    "    \n",
    "    # Test Contextual Compression retriever\n",
    "    compression_response = compression_retrieval_chain.invoke({\"question\": query})\n",
    "    print(f\"Contextual Compression: {len(compression_response['context'])} docs retrieved\")\n",
    "\n",
    "print(\"\\n✅ Advanced retrieval techniques tested successfully!\")\n",
    "print(\"✅ BM25 provides keyword-based medical information retrieval\")\n",
    "print(\"✅ Contextual Compression filters irrelevant medical information\")\n",
    "print(\"✅ Both techniques ready for RAGAS evaluation comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 6: Advanced Retrieval Techniques - COMPLETION ===\n",
      "\n",
      "5. Why These Techniques Are Useful for Medical Use Case:\n",
      "✅ BM25 Retriever:\n",
      "BM25 is useful for medical queries because it excels at exact keyword matching for specific drug names, symptoms, and medical conditions.\n",
      "\n",
      "✅ Contextual Compression (Cohere Reranking):\n",
      "Contextual Compression is useful for medical information because it filters out irrelevant medical data and ensures only highly relevant treatment/symptom information is retrieved.\n",
      "\n",
      "6. RAGAS Evaluation of Advanced Retrievers...\n",
      "\n",
      "=== Evaluating BM25 Retriever ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da7b483fa704e34b189c30ea1e5cae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�� BM25 Retriever RAGAS Results:\n",
      "{'context_recall': 1.0000, 'context_precision': 0.9676, 'faithfulness': 0.8405, 'factual_correctness': 0.6283, 'answer_relevancy': 0.7894, 'context_entity_recall': 0.3943, 'noise_sensitivity_relevant': 0.2046}\n",
      "\n",
      "=== Evaluating Contextual Compression Retriever ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4ea28e1de34d4987ecbc65d17ff776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Contextual Compression Retriever RAGAS Results:\n",
      "{'context_recall': 1.0000, 'context_precision': 1.0000, 'faithfulness': 0.8765, 'factual_correctness': 0.4933, 'answer_relevancy': 0.7857, 'context_entity_recall': 0.4838, 'noise_sensitivity_relevant': 0.3487}\n",
      "\n",
      "✅ Task 6 COMPLETE with all requirements!\n",
      "✅ Advanced retrieval techniques described and evaluated\n",
      "✅ Performance comparison with RAGAS metrics completed\n",
      "✅ Rate limiting properly handled for Cohere API\n"
     ]
    }
   ],
   "source": [
    "# Task 6: The Benefits of Advanced Retrieval - COMPLETION\n",
    "\n",
    "print(\"=== Task 6: Advanced Retrieval Techniques - COMPLETION ===\")\n",
    "\n",
    "import time\n",
    "\n",
    "# ===== 5. One Sentence Explanations (Missing Requirement) =====\n",
    "\n",
    "print(\"\\n5. Why These Techniques Are Useful for Medical Use Case:\")\n",
    "\n",
    "print(\"✅ BM25 Retriever:\")\n",
    "print(\"BM25 is useful for medical queries because it excels at exact keyword matching for specific drug names, symptoms, and medical conditions.\")\n",
    "\n",
    "print(\"\\n✅ Contextual Compression (Cohere Reranking):\")\n",
    "print(\"Contextual Compression is useful for medical information because it filters out irrelevant medical data and ensures only highly relevant treatment/symptom information is retrieved.\")\n",
    "\n",
    "# ===== 6. RAGAS Evaluation of Advanced Retrievers (Missing Requirement) =====\n",
    "\n",
    "print(\"\\n6. RAGAS Evaluation of Advanced Retrievers...\")\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "\n",
    "# Core RAGAS metrics - SAME AS TASK 5\n",
    "ragas_metrics = [\n",
    "    ContextRecall(),                        # ✅ Traditional - Medical database coverage\n",
    "    ContextPrecision(llm=evaluator_llm),   # ✅ Medical information relevance\n",
    "    LLMContextRecall(),                     # ✅ Response coverage of retrieved medical info\n",
    "    Faithfulness(),                         # ✅ Medical accuracy adherence\n",
    "    FactualCorrectness(),                   # ✅ Medical fact verification\n",
    "    ResponseRelevancy(),                    # ✅ Medical query-response alignment\n",
    "    ContextEntityRecall(),                  # ✅ Medical entity recognition\n",
    "    NoiseSensitivity()                      # ✅ Medical information filtering\n",
    "]\n",
    "\n",
    "custom_run_config = RunConfig(timeout=300)\n",
    "\n",
    "# Function to create evaluation chain (SAME AS TASK 5)\n",
    "def create_evaluation_chain(retriever, name):\n",
    "    return (\n",
    "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "        | rag_prompt | llm | StrOutputParser()\n",
    "    )\n",
    "\n",
    "print(\"\\n=== Evaluating BM25 Retriever ===\")\n",
    "bm25_eval_chain = create_evaluation_chain(bm25_retriever, \"bm25\")\n",
    "\n",
    "# Evaluate BM25 retriever (SAME PROCESS AS TASK 5)\n",
    "for test_row in ragas_dataset:\n",
    "    response = bm25_eval_chain.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response\n",
    "    test_row.eval_sample.retrieved_contexts = [doc.page_content for doc in bm25_retriever.invoke(test_row.eval_sample.user_input)]\n",
    "\n",
    "bm25_evaluation_dataset = EvaluationDataset.from_pandas(ragas_dataset.to_pandas())\n",
    "\n",
    "from ragas import evaluate as ragas_evaluate\n",
    "\n",
    "bm25_result = ragas_evaluate(\n",
    "    dataset=bm25_evaluation_dataset,\n",
    "    metrics=ragas_metrics,\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config\n",
    ")\n",
    "\n",
    "print(\"�� BM25 Retriever RAGAS Results:\")\n",
    "print(bm25_result)\n",
    "\n",
    "print(\"\\n=== Evaluating Contextual Compression Retriever ===\")\n",
    "\n",
    "# Add delay before Contextual Compression evaluation (SAME AS Advanced_Retrieval notebook)\n",
    "time.sleep(60)  # Wait 1 minute before retrying\n",
    "\n",
    "compression_eval_chain = create_evaluation_chain(compression_retriever, \"compression\")\n",
    "\n",
    "# Evaluate Contextual Compression retriever (SAME PROCESS AS TASK 5 with rate limiting)\n",
    "for i, test_row in enumerate(ragas_dataset):\n",
    "    try:\n",
    "        response = compression_eval_chain.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "        test_row.eval_sample.response = response\n",
    "        test_row.eval_sample.retrieved_contexts = [doc.page_content for doc in compression_retriever.invoke(test_row.eval_sample.user_input)]\n",
    "        \n",
    "        # Add delay between calls to avoid rate limits (10 calls/minute = 6 seconds between calls)\n",
    "        if i < len(ragas_dataset) - 1:  # Don't delay after the last call\n",
    "            time.sleep(6)  # Wait 6 seconds between each call\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing test case {i+1}: {e}\")\n",
    "        # If rate limited, wait longer and retry\n",
    "        if \"TooManyRequestsError\" in str(e):\n",
    "            print(\"🔄 Rate limited, waiting 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "        continue\n",
    "\n",
    "compression_evaluation_dataset = EvaluationDataset.from_pandas(ragas_dataset.to_pandas())\n",
    "\n",
    "compression_result = ragas_evaluate(\n",
    "    dataset=compression_evaluation_dataset,\n",
    "    metrics=ragas_metrics,\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config\n",
    ")\n",
    "\n",
    "print(\"📊 Contextual Compression Retriever RAGAS Results:\")\n",
    "print(compression_result)\n",
    "\n",
    "print(\"\\n✅ Task 6 COMPLETE with all requirements!\")\n",
    "print(\"✅ Advanced retrieval techniques described and evaluated\")\n",
    "print(\"✅ Performance comparison with RAGAS metrics completed\")\n",
    "print(\"✅ Rate limiting properly handled for Cohere API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 7 : Assessing Performance (Basic RAG vs Advanced Retrievers - RAG)\n",
    "\n",
    "This is explained clearly in the Written_Document (markdown file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# �� IMPORTANT: COMPREHENSIVE DOCUMENTATION AVAILABLE\n",
    "\n",
    "**For detailed explanations of each task, comprehensive analysis, and complete documentation, please refer to the markdown file: `Written_Document_Personal_Health_Copilot.md`**\n",
    "\n",
    "## �� This markdown file contains:\n",
    "- **Complete task-by-task explanations** with professional formatting\n",
    "- **Detailed technical implementations** and architecture decisions  \n",
    "- **Performance analysis and RAGAS evaluation results** with quantified metrics\n",
    "- **Future development roadmap** with prioritized improvements\n",
    "- **Professional documentation** suitable for grading purposes\n",
    "\n",
    "## 🔗 File Relationship:\n",
    "- **Notebook**: Provides implementation code and execution results\n",
    "- **Markdown**: Provides comprehensive written documentation for submission\n",
    "\n",
    "## ✅ Project Status:\n",
    "**COMPLETE** - Both files work together to provide complete project documentation for the Personal Health Copilot Certification Challenge.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** This notebook contains the implementation code and execution results, while the markdown file provides the detailed written explanations required for the certification challenge submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
